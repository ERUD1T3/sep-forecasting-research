{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "422/422 [==============================] - 8s 8ms/step - loss: 0.0296 - accuracy: 0.8708 - val_loss: 0.0144 - val_accuracy: 0.9550\n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0133 - accuracy: 0.9510 - val_loss: 0.0102 - val_accuracy: 0.9685\n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0097 - accuracy: 0.9663 - val_loss: 0.0082 - val_accuracy: 0.9733\n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0077 - accuracy: 0.9742 - val_loss: 0.0074 - val_accuracy: 0.9752\n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0063 - accuracy: 0.9800 - val_loss: 0.0067 - val_accuracy: 0.9767\n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 4s 8ms/step - loss: 0.0053 - accuracy: 0.9844 - val_loss: 0.0061 - val_accuracy: 0.9782\n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0046 - accuracy: 0.9876 - val_loss: 0.0056 - val_accuracy: 0.9785\n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0039 - accuracy: 0.9903 - val_loss: 0.0054 - val_accuracy: 0.9803\n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9924 - val_loss: 0.0050 - val_accuracy: 0.9787\n",
      "Epoch 10/10\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9939 - val_loss: 0.0050 - val_accuracy: 0.9782\n",
      "\n",
      "Test accuracy (noisy): 0.9753\n",
      "Test loss (MSE, noisy): 0.0056\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Manual verification - Test accuracy (noisy): 0.9753\n",
      "\n",
      "Test accuracy (clean): 0.9708\n",
      "Test loss (MSE, clean): 0.0101\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize and reshape the data\n",
    "x_train = x_train.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "\n",
    "# Add Gaussian noise to the data (doubled noise factor)\n",
    "noise_factor = 0.1  # Increased from 0.5 to 1.0\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "# Clip the noisy images to be between 0 and 1\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Create a simple MLP model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Compile model with MSE loss\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model with noisy data\n",
    "history = model.fit(\n",
    "    x_train_noisy, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test set with noisy data\n",
    "test_loss, test_accuracy = model.evaluate(x_test_noisy, y_test, verbose=0)\n",
    "print(f\"\\nTest accuracy (noisy): {test_accuracy:.4f}\")\n",
    "print(f\"Test loss (MSE, noisy): {test_loss:.4f}\")\n",
    "\n",
    "# Make predictions on noisy test data and calculate accuracy manually to verify\n",
    "y_pred = model.predict(x_test_noisy)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "manual_accuracy = np.mean(y_pred_classes == y_test_classes)\n",
    "print(f\"Manual verification - Test accuracy (noisy): {manual_accuracy:.4f}\")\n",
    "\n",
    "# For comparison, evaluate on clean test data\n",
    "clean_test_loss, clean_test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nTest accuracy (clean): {clean_test_accuracy:.4f}\")\n",
    "print(f\"Test loss (MSE, clean): {clean_test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "422/422 [==============================] - 5s 10ms/step - loss: 0.1775 - accuracy: 0.9011 - val_loss: 0.0830 - val_accuracy: 0.9632\n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 4s 8ms/step - loss: 0.0786 - accuracy: 0.9586 - val_loss: 0.0596 - val_accuracy: 0.9702\n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 4s 8ms/step - loss: 0.0562 - accuracy: 0.9720 - val_loss: 0.0495 - val_accuracy: 0.9740\n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0442 - accuracy: 0.9788 - val_loss: 0.0437 - val_accuracy: 0.9758\n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0361 - accuracy: 0.9834 - val_loss: 0.0400 - val_accuracy: 0.9783\n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0301 - accuracy: 0.9869 - val_loss: 0.0370 - val_accuracy: 0.9792\n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0253 - accuracy: 0.9901 - val_loss: 0.0350 - val_accuracy: 0.9792\n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0210 - accuracy: 0.9921 - val_loss: 0.0317 - val_accuracy: 0.9783\n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.0315 - val_accuracy: 0.9777\n",
      "Epoch 10/10\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.0308 - val_accuracy: 0.9788\n",
      "\n",
      "Custom Loss - Test accuracy (noisy): 0.9756\n",
      "Custom Loss - Test loss (noisy): 0.0339\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Custom Loss - Manual verification accuracy (noisy): 0.9756\n",
      "\n",
      "Custom Loss - Test accuracy (clean): 0.9713\n",
      "Custom Loss - Test loss (clean): 0.0515\n",
      "\n",
      "Comparison:\n",
      "Original MSE - Test accuracy (noisy): 0.9753\n",
      "Custom Loss - Test accuracy (noisy): 0.9756\n",
      "Original MSE - Test accuracy (clean): 0.9708\n",
      "Custom Loss - Test accuracy (clean): 0.9713\n"
     ]
    }
   ],
   "source": [
    "# Create a custom loss function combining MSE and PCC\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # MSE term\n",
    "    mse = tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "    \n",
    "    # PCC term\n",
    "    y_true_centered = y_true - tf.reduce_mean(y_true) \n",
    "    y_pred_centered = y_pred - tf.reduce_mean(y_pred)\n",
    "    \n",
    "    cov = tf.reduce_sum(y_true_centered * y_pred_centered)\n",
    "    std_y_true = tf.sqrt(tf.reduce_sum(tf.square(y_true_centered)))\n",
    "    std_y_pred = tf.sqrt(tf.reduce_sum(tf.square(y_pred_centered)))\n",
    "    \n",
    "    pcc = cov / (std_y_true * std_y_pred + K.epsilon())\n",
    "    \n",
    "    # Calculate coefficient to match MSE range\n",
    "    y_true_min = tf.reduce_min(y_true)\n",
    "    y_true_max = tf.reduce_max(y_true)\n",
    "    coef = tf.abs(y_true_max - y_true_min)  # Maximum possible MSE value\n",
    "    \n",
    "    # Combined loss with coefficient matching MSE range\n",
    "    return mse + coef * (1.0 - pcc)\n",
    "\n",
    "# Create the same MLP model\n",
    "model_custom = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Compile with custom loss\n",
    "model_custom.compile(\n",
    "    optimizer='adam',\n",
    "    loss=custom_loss,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model with noisy data\n",
    "history_custom = model_custom.fit(\n",
    "    x_train_noisy, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test set with noisy data\n",
    "test_loss_custom, test_accuracy_custom = model_custom.evaluate(x_test_noisy, y_test, verbose=0)\n",
    "print(f\"\\nCustom Loss - Test accuracy (noisy): {test_accuracy_custom:.4f}\")\n",
    "print(f\"Custom Loss - Test loss (noisy): {test_loss_custom:.4f}\")\n",
    "\n",
    "# Manual verification with noisy data\n",
    "y_pred_custom = model_custom.predict(x_test_noisy)\n",
    "y_pred_custom_classes = np.argmax(y_pred_custom, axis=1)\n",
    "manual_accuracy_custom = np.mean(y_pred_custom_classes == y_test_classes)\n",
    "print(f\"Custom Loss - Manual verification accuracy (noisy): {manual_accuracy_custom:.4f}\")\n",
    "\n",
    "# For comparison, evaluate on clean test data\n",
    "clean_test_loss_custom, clean_test_accuracy_custom = model_custom.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nCustom Loss - Test accuracy (clean): {clean_test_accuracy_custom:.4f}\")\n",
    "print(f\"Custom Loss - Test loss (clean): {clean_test_loss_custom:.4f}\")\n",
    "\n",
    "# Compare results\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"Original MSE - Test accuracy (noisy): {test_accuracy:.4f}\")\n",
    "print(f\"Custom Loss - Test accuracy (noisy): {test_accuracy_custom:.4f}\")\n",
    "print(f\"Original MSE - Test accuracy (clean): {clean_test_accuracy:.4f}\")\n",
    "print(f\"Custom Loss - Test accuracy (clean): {clean_test_accuracy_custom:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0949 - accuracy: 0.1101 - val_loss: 0.0902 - val_accuracy: 0.1192\n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0897 - accuracy: 0.1337 - val_loss: 0.0895 - val_accuracy: 0.1263\n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0887 - accuracy: 0.1693 - val_loss: 0.0883 - val_accuracy: 0.1828\n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0873 - accuracy: 0.2076 - val_loss: 0.0870 - val_accuracy: 0.2157\n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0861 - accuracy: 0.2270 - val_loss: 0.0861 - val_accuracy: 0.2287\n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0854 - accuracy: 0.2393 - val_loss: 0.0857 - val_accuracy: 0.2343\n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0848 - accuracy: 0.2533 - val_loss: 0.0851 - val_accuracy: 0.2502\n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0840 - accuracy: 0.2679 - val_loss: 0.0847 - val_accuracy: 0.2518\n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0832 - accuracy: 0.2803 - val_loss: 0.0850 - val_accuracy: 0.2538\n",
      "Epoch 10/10\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0825 - accuracy: 0.2913 - val_loss: 0.0838 - val_accuracy: 0.2760\n",
      "\n",
      "Test accuracy (noisy): 0.2697\n",
      "Test loss (MSE, noisy): 0.0842\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Manual verification - Test accuracy (noisy): 0.2697\n",
      "\n",
      "Test accuracy (clean): 0.6468\n",
      "Test loss (MSE, clean): 0.0624\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize and reshape the data\n",
    "x_train = x_train.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "\n",
    "# Add Gaussian noise to the data (doubled noise factor)\n",
    "noise_factor = 3  # Increased from 0.5 to 1.0\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "# Clip the noisy images to be between 0 and 1\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Create a simple MLP model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Compile model with MSE loss\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model with noisy data\n",
    "history = model.fit(\n",
    "    x_train_noisy, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test set with noisy data\n",
    "test_loss, test_accuracy = model.evaluate(x_test_noisy, y_test, verbose=0)\n",
    "print(f\"\\nTest accuracy (noisy): {test_accuracy:.4f}\")\n",
    "print(f\"Test loss (MSE, noisy): {test_loss:.4f}\")\n",
    "\n",
    "# Make predictions on noisy test data and calculate accuracy manually to verify\n",
    "y_pred = model.predict(x_test_noisy)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "manual_accuracy = np.mean(y_pred_classes == y_test_classes)\n",
    "print(f\"Manual verification - Test accuracy (noisy): {manual_accuracy:.4f}\")\n",
    "\n",
    "# For comparison, evaluate on clean test data\n",
    "clean_test_loss, clean_test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nTest accuracy (clean): {clean_test_accuracy:.4f}\")\n",
    "print(f\"Test loss (MSE, clean): {clean_test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "422/422 [==============================] - 5s 10ms/step - loss: 0.9966 - accuracy: 0.1639 - val_loss: 0.8944 - val_accuracy: 0.2215\n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.8719 - accuracy: 0.2389 - val_loss: 0.8904 - val_accuracy: 0.2243\n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.8442 - accuracy: 0.2546 - val_loss: 0.8562 - val_accuracy: 0.2495\n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.8269 - accuracy: 0.2658 - val_loss: 0.8444 - val_accuracy: 0.2632\n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.8089 - accuracy: 0.2779 - val_loss: 0.8419 - val_accuracy: 0.2600\n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.7968 - accuracy: 0.2882 - val_loss: 0.8394 - val_accuracy: 0.2573\n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.7784 - accuracy: 0.3022 - val_loss: 0.8248 - val_accuracy: 0.2720\n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.7644 - accuracy: 0.3136 - val_loss: 0.8267 - val_accuracy: 0.2705\n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.7487 - accuracy: 0.3252 - val_loss: 0.8326 - val_accuracy: 0.2702\n",
      "Epoch 10/10\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.7350 - accuracy: 0.3374 - val_loss: 0.8233 - val_accuracy: 0.2750\n",
      "\n",
      "Custom Loss - Test accuracy (noisy): 0.2705\n",
      "Custom Loss - Test loss (noisy): 0.8319\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Custom Loss - Manual verification accuracy (noisy): 0.2705\n",
      "\n",
      "Custom Loss - Test accuracy (clean): 0.6746\n",
      "Custom Loss - Test loss (clean): 0.4865\n",
      "\n",
      "Comparison:\n",
      "Original MSE - Test accuracy (noisy): 0.2697\n",
      "Custom Loss - Test accuracy (noisy): 0.2705\n",
      "Original MSE - Test accuracy (clean): 0.6468\n",
      "Custom Loss - Test accuracy (clean): 0.6746\n"
     ]
    }
   ],
   "source": [
    "# Create a custom loss function combining MSE and PCC\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # MSE term\n",
    "    mse = tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "    \n",
    "    # PCC term\n",
    "    y_true_centered = y_true - tf.reduce_mean(y_true) \n",
    "    y_pred_centered = y_pred - tf.reduce_mean(y_pred)\n",
    "    \n",
    "    cov = tf.reduce_sum(y_true_centered * y_pred_centered)\n",
    "    std_y_true = tf.sqrt(tf.reduce_sum(tf.square(y_true_centered)))\n",
    "    std_y_pred = tf.sqrt(tf.reduce_sum(tf.square(y_pred_centered)))\n",
    "    \n",
    "    pcc = cov / (std_y_true * std_y_pred + K.epsilon())\n",
    "    \n",
    "    # Calculate coefficient to match MSE range\n",
    "    y_true_min = tf.reduce_min(y_true)\n",
    "    y_true_max = tf.reduce_max(y_true)\n",
    "    coef = tf.abs(y_true_max - y_true_min)  # Maximum possible MSE value\n",
    "    \n",
    "    # Combined loss with coefficient matching MSE range\n",
    "    return mse + coef * (1.0 - pcc)\n",
    "\n",
    "# Create the same MLP model\n",
    "model_custom = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Compile with custom loss\n",
    "model_custom.compile(\n",
    "    optimizer='adam',\n",
    "    loss=custom_loss,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model with noisy data\n",
    "history_custom = model_custom.fit(\n",
    "    x_train_noisy, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test set with noisy data\n",
    "test_loss_custom, test_accuracy_custom = model_custom.evaluate(x_test_noisy, y_test, verbose=0)\n",
    "print(f\"\\nCustom Loss - Test accuracy (noisy): {test_accuracy_custom:.4f}\")\n",
    "print(f\"Custom Loss - Test loss (noisy): {test_loss_custom:.4f}\")\n",
    "\n",
    "# Manual verification with noisy data\n",
    "y_pred_custom = model_custom.predict(x_test_noisy)\n",
    "y_pred_custom_classes = np.argmax(y_pred_custom, axis=1)\n",
    "manual_accuracy_custom = np.mean(y_pred_custom_classes == y_test_classes)\n",
    "print(f\"Custom Loss - Manual verification accuracy (noisy): {manual_accuracy_custom:.4f}\")\n",
    "\n",
    "# For comparison, evaluate on clean test data\n",
    "clean_test_loss_custom, clean_test_accuracy_custom = model_custom.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nCustom Loss - Test accuracy (clean): {clean_test_accuracy_custom:.4f}\")\n",
    "print(f\"Custom Loss - Test loss (clean): {clean_test_loss_custom:.4f}\")\n",
    "\n",
    "# Compare results\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"Original MSE - Test accuracy (noisy): {test_accuracy:.4f}\")\n",
    "print(f\"Custom Loss - Test accuracy (noisy): {test_accuracy_custom:.4f}\")\n",
    "print(f\"Original MSE - Test accuracy (clean): {clean_test_accuracy:.4f}\")\n",
    "print(f\"Custom Loss - Test accuracy (clean): {clean_test_accuracy_custom:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set:\n",
      "Digit 0: 5923 samples\n",
      "Digit 1: 5393 samples\n",
      "Digit 2: 3574 samples\n",
      "Digit 3: 2452 samples\n",
      "Digit 4: 1752 samples\n",
      "Digit 5: 1355 samples\n",
      "Digit 6: 1183 samples\n",
      "Digit 7: 939 samples\n",
      "Digit 8: 585 samples\n",
      "Digit 9: 297 samples\n",
      "Epoch 1/10\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0969 - accuracy: 0.3525 - val_loss: 0.0711 - val_accuracy: 0.4817\n",
      "Epoch 2/10\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0644 - accuracy: 0.5267 - val_loss: 0.0587 - val_accuracy: 0.5759\n",
      "Epoch 3/10\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0551 - accuracy: 0.6121 - val_loss: 0.0528 - val_accuracy: 0.6394\n",
      "Epoch 4/10\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0497 - accuracy: 0.6682 - val_loss: 0.0492 - val_accuracy: 0.6675\n",
      "Epoch 5/10\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0462 - accuracy: 0.6956 - val_loss: 0.0479 - val_accuracy: 0.6718\n",
      "Epoch 6/10\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0435 - accuracy: 0.7144 - val_loss: 0.0460 - val_accuracy: 0.6897\n",
      "Epoch 7/10\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.0413 - accuracy: 0.7329 - val_loss: 0.0443 - val_accuracy: 0.7012\n",
      "Epoch 8/10\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0394 - accuracy: 0.7531 - val_loss: 0.0434 - val_accuracy: 0.7191\n",
      "Epoch 9/10\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.0376 - accuracy: 0.7690 - val_loss: 0.0424 - val_accuracy: 0.7165\n",
      "Epoch 10/10\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.7825 - val_loss: 0.0419 - val_accuracy: 0.7234\n",
      "\n",
      "Test accuracy (noisy): 0.5147\n",
      "Test loss (MSE, noisy): 0.0653\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "\n",
      "Per-class accuracy:\n",
      "Digit 0: 0.9408\n",
      "Digit 1: 0.9322\n",
      "Digit 2: 0.7025\n",
      "Digit 3: 0.7465\n",
      "Digit 4: 0.7536\n",
      "Digit 5: 0.1726\n",
      "Digit 6: 0.4207\n",
      "Digit 7: 0.3804\n",
      "Digit 8: 0.0000\n",
      "Digit 9: 0.0000\n",
      "\n",
      "Test accuracy (clean): 0.6397\n",
      "Test loss (MSE, clean): 0.0786\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize and reshape the data\n",
    "x_train = x_train.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "\n",
    "# Create imbalanced dataset with variable ratios\n",
    "# Define imbalance ratios for each digit (0-9)\n",
    "imbalance_ratios = {\n",
    "    0: 1.0,    # Keep all samples\n",
    "    1: 0.8,    # Keep 80% of samples\n",
    "    2: 0.6,    # Keep 60% of samples\n",
    "    3: 0.4,    # Keep 40% of samples\n",
    "    4: 0.3,    # Keep 30% of samples\n",
    "    5: 0.25,   # Keep 25% of samples\n",
    "    6: 0.2,    # Keep 20% of samples\n",
    "    7: 0.15,   # Keep 15% of samples\n",
    "    8: 0.1,    # Keep 10% of samples\n",
    "    9: 0.05    # Keep 5% of samples\n",
    "}\n",
    "\n",
    "# Create masks for imbalanced sampling\n",
    "train_indices = []\n",
    "for digit in range(10):\n",
    "    digit_indices = np.where(y_train == digit)[0]\n",
    "    num_samples = int(len(digit_indices) * imbalance_ratios[digit])\n",
    "    selected_indices = np.random.choice(digit_indices, num_samples, replace=False)\n",
    "    train_indices.extend(selected_indices)\n",
    "\n",
    "train_indices = np.array(train_indices)\n",
    "np.random.shuffle(train_indices)\n",
    "\n",
    "# Select the imbalanced subset\n",
    "x_train = x_train[train_indices]\n",
    "y_train = y_train[train_indices]\n",
    "\n",
    "# Add Gaussian noise to the data\n",
    "noise_factor = 1.0\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "# Clip the noisy images to be between 0 and 1\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Print class distribution\n",
    "print(\"Class distribution in training set:\")\n",
    "for i in range(10):\n",
    "    count = np.sum(np.argmax(y_train, axis=1) == i)\n",
    "    print(f\"Digit {i}: {count} samples\")\n",
    "\n",
    "# Create a simple MLP model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Compile model with MSE loss\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model with noisy data\n",
    "history = model.fit(\n",
    "    x_train_noisy, y_train,\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test set with noisy data\n",
    "test_loss, test_accuracy = model.evaluate(x_test_noisy, y_test, verbose=0)\n",
    "print(f\"\\nTest accuracy (noisy): {test_accuracy:.4f}\")\n",
    "print(f\"Test loss (MSE, noisy): {test_loss:.4f}\")\n",
    "\n",
    "# Make predictions and calculate per-class accuracy\n",
    "y_pred = model.predict(x_test_noisy)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"\\nPer-class accuracy:\")\n",
    "for i in range(10):\n",
    "    mask = (y_test_classes == i)\n",
    "    class_acc = np.mean(y_pred_classes[mask] == y_test_classes[mask])\n",
    "    print(f\"Digit {i}: {class_acc:.4f}\")\n",
    "\n",
    "# For comparison, evaluate on clean test data\n",
    "clean_test_loss, clean_test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nTest accuracy (clean): {clean_test_accuracy:.4f}\")\n",
    "print(f\"Test loss (MSE, clean): {clean_test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.6363 - accuracy: 0.4705 - val_loss: 0.4770 - val_accuracy: 0.5882\n",
      "Epoch 2/10\n",
      "83/83 [==============================] - 1s 10ms/step - loss: 0.4196 - accuracy: 0.6368 - val_loss: 0.3984 - val_accuracy: 0.6505\n",
      "Epoch 3/10\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.3523 - accuracy: 0.6954 - val_loss: 0.3557 - val_accuracy: 0.6888\n",
      "Epoch 4/10\n",
      "83/83 [==============================] - 0s 6ms/step - loss: 0.3096 - accuracy: 0.7321 - val_loss: 0.3302 - val_accuracy: 0.7008\n",
      "Epoch 5/10\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.2803 - accuracy: 0.7587 - val_loss: 0.3205 - val_accuracy: 0.7140\n",
      "Epoch 6/10\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.2610 - accuracy: 0.7766 - val_loss: 0.3124 - val_accuracy: 0.7208\n",
      "Epoch 7/10\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.2437 - accuracy: 0.7912 - val_loss: 0.3025 - val_accuracy: 0.7191\n",
      "Epoch 8/10\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2282 - accuracy: 0.8055 - val_loss: 0.2964 - val_accuracy: 0.7370\n",
      "Epoch 9/10\n",
      "83/83 [==============================] - 1s 7ms/step - loss: 0.2148 - accuracy: 0.8212 - val_loss: 0.2938 - val_accuracy: 0.7361\n",
      "Epoch 10/10\n",
      "83/83 [==============================] - 1s 6ms/step - loss: 0.2008 - accuracy: 0.8350 - val_loss: 0.2977 - val_accuracy: 0.7336\n",
      "\n",
      "Custom Loss - Test accuracy (noisy): 0.5664\n",
      "Custom Loss - Test loss (noisy): 0.4737\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "\n",
      "Custom Loss - Per-class accuracy:\n",
      "Digit 0: 0.9010\n",
      "Digit 1: 0.9269\n",
      "Digit 2: 0.6986\n",
      "Digit 3: 0.6911\n",
      "Digit 4: 0.7536\n",
      "Digit 5: 0.2993\n",
      "Digit 6: 0.6712\n",
      "Digit 7: 0.6391\n",
      "Digit 8: 0.0031\n",
      "Digit 9: 0.0000\n",
      "\n",
      "Custom Loss - Test accuracy (clean): 0.6680\n",
      "Custom Loss - Test loss (clean): 0.4633\n",
      "\n",
      "Comparison:\n",
      "Original MSE - Test accuracy (noisy): 0.5147\n",
      "Custom Loss - Test accuracy (noisy): 0.5664\n",
      "Original MSE - Test accuracy (clean): 0.6397\n",
      "Custom Loss - Test accuracy (clean): 0.6680\n"
     ]
    }
   ],
   "source": [
    "# Create a custom loss function combining MSE and PCC\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # MSE term\n",
    "    mse = tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "    \n",
    "    # PCC term\n",
    "    y_true_centered = y_true - tf.reduce_mean(y_true) \n",
    "    y_pred_centered = y_pred - tf.reduce_mean(y_pred)\n",
    "    \n",
    "    cov = tf.reduce_sum(y_true_centered * y_pred_centered)\n",
    "    std_y_true = tf.sqrt(tf.reduce_sum(tf.square(y_true_centered)))\n",
    "    std_y_pred = tf.sqrt(tf.reduce_sum(tf.square(y_pred_centered)))\n",
    "    \n",
    "    pcc = cov / (std_y_true * std_y_pred + K.epsilon())\n",
    "    \n",
    "    # Calculate coefficient to match MSE range\n",
    "    y_true_min = tf.reduce_min(y_true)\n",
    "    y_true_max = tf.reduce_max(y_true)\n",
    "    coef = tf.abs(y_true_max - y_true_min)  # Maximum possible MSE value\n",
    "    \n",
    "    # Combined loss with coefficient matching MSE range\n",
    "    return mse + coef * (1.0 - pcc)\n",
    "\n",
    "# Create the same MLP model\n",
    "model_custom = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Compile with custom loss\n",
    "model_custom.compile(\n",
    "    optimizer='adam',\n",
    "    loss=custom_loss,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model with noisy data\n",
    "history_custom = model_custom.fit(\n",
    "    x_train_noisy, y_train,\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test set with noisy data\n",
    "test_loss_custom, test_accuracy_custom = model_custom.evaluate(x_test_noisy, y_test, verbose=0)\n",
    "print(f\"\\nCustom Loss - Test accuracy (noisy): {test_accuracy_custom:.4f}\")\n",
    "print(f\"Custom Loss - Test loss (noisy): {test_loss_custom:.4f}\")\n",
    "\n",
    "# Make predictions and calculate per-class accuracy\n",
    "y_pred_custom = model_custom.predict(x_test_noisy)\n",
    "y_pred_custom_classes = np.argmax(y_pred_custom, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"\\nCustom Loss - Per-class accuracy:\")\n",
    "for i in range(10):\n",
    "    mask = (y_test_classes == i)\n",
    "    class_acc = np.mean(y_pred_custom_classes[mask] == y_test_classes[mask])\n",
    "    print(f\"Digit {i}: {class_acc:.4f}\")\n",
    "\n",
    "# For comparison, evaluate on clean test data\n",
    "clean_test_loss_custom, clean_test_accuracy_custom = model_custom.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nCustom Loss - Test accuracy (clean): {clean_test_accuracy_custom:.4f}\")\n",
    "print(f\"Custom Loss - Test loss (clean): {clean_test_loss_custom:.4f}\")\n",
    "\n",
    "# Compare results\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"Original MSE - Test accuracy (noisy): {test_accuracy:.4f}\")\n",
    "print(f\"Custom Loss - Test accuracy (noisy): {test_accuracy_custom:.4f}\")\n",
    "print(f\"Original MSE - Test accuracy (clean): {clean_test_accuracy:.4f}\")\n",
    "print(f\"Custom Loss - Test accuracy (clean): {clean_test_accuracy_custom:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
