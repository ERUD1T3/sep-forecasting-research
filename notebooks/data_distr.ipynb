{
 "cells": [
  {
   "cell_type": "code",
   "id": "7bbef6f74a7412b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:31:20.589196Z",
     "start_time": "2024-11-28T14:31:10.343642Z"
    }
   },
   "source": [
    "from modules.shared.globals import *\n",
    "from modules.training.cme_modeling import ModelBuilder\n",
    "from modules.training.ts_modeling import (\n",
    "    build_dataset,\n",
    "    load_stratified_folds,\n",
    "    set_seed)\n",
    "import numpy as np\n",
    "from modules.training.ts_modeling import get_plus_cls, get_zero_cls, get_minus_cls, convert_to_onehot_cls\n",
    "mb = ModelBuilder()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\the_3\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\the_3\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "ee09b784c5fd4d01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:26:59.103350Z",
     "start_time": "2024-11-28T14:26:32.728001Z"
    }
   },
   "source": [
    "seed = SEEDS[0]\n",
    "inputs_to_use = INPUTS_TO_USE[0]\n",
    "add_slope = ADD_SLOPE[0]\n",
    "cme_speed_threshold = CME_SPEED_THRESHOLD[0]\n",
    "outputs_to_use = OUTPUTS_TO_USE\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "# set the root directory\n",
    "root_dir = 'C:/Users/the_3/Documents/github/keras-functional-api/data/electron_cme_data_split_v8'\n",
    "# root_dir = 'D:/College/Fall2023/sep-forecasting-research/data/electron_cme_data_split_v8'\n",
    "# build the dataset\n",
    "X_train, y_train, _, _ = build_dataset(\n",
    "    root_dir + '/training',\n",
    "    inputs_to_use=inputs_to_use,\n",
    "    add_slope=add_slope,\n",
    "    outputs_to_use=outputs_to_use,\n",
    "    cme_speed_threshold=cme_speed_threshold,\n",
    "    shuffle_data=True)\n",
    "\n",
    "X_test, y_test, _, _ = build_dataset(\n",
    "    root_dir + '/testing',\n",
    "    inputs_to_use=inputs_to_use,\n",
    "    add_slope=add_slope,\n",
    "    outputs_to_use=outputs_to_use,\n",
    "    cme_speed_threshold=cme_speed_threshold)\n",
    "\n",
    "folds = []\n",
    "for fold_data in load_stratified_folds(\n",
    "    root_dir,\n",
    "    inputs_to_use=inputs_to_use,\n",
    "    add_slope=add_slope,\n",
    "    outputs_to_use=outputs_to_use,\n",
    "    cme_speed_threshold=cme_speed_threshold,\n",
    "    seed=seed,\n",
    "    shuffle=True\n",
    "):\n",
    "    folds.append(fold_data)\n",
    "\n",
    "# Print training and test shapes\n",
    "print(\"Training and Test Shapes:\")\n",
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}') \n",
    "print(f'y_test.shape: {y_test.shape}')\n",
    "print()\n",
    "\n",
    "# Print shapes for each fold\n",
    "for i, (X_sub, y_sub, X_v, y_v) in enumerate(folds):\n",
    "    print(f'Fold {i+1}:')\n",
    "    print(f'X_subtrain.shape: {X_sub.shape}')\n",
    "    print(f'y_subtrain.shape: {y_sub.shape}')\n",
    "    print(f'X_val.shape: {X_v.shape}')\n",
    "    print(f'y_val.shape: {y_v.shape}')\n",
    "    print()\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Test Shapes:\n",
      "X_train.shape: (16720, 124)\n",
      "y_train.shape: (16720, 1)\n",
      "X_test.shape: (11839, 124)\n",
      "y_test.shape: (11839, 1)\n",
      "\n",
      "Fold 1:\n",
      "X_subtrain.shape: (11955, 124)\n",
      "y_subtrain.shape: (11955, 1)\n",
      "X_val.shape: (4765, 124)\n",
      "y_val.shape: (4765, 1)\n",
      "\n",
      "Fold 2:\n",
      "X_subtrain.shape: (12177, 124)\n",
      "y_subtrain.shape: (12177, 1)\n",
      "X_val.shape: (4543, 124)\n",
      "y_val.shape: (4543, 1)\n",
      "\n",
      "Fold 3:\n",
      "X_subtrain.shape: (11855, 124)\n",
      "y_subtrain.shape: (11855, 1)\n",
      "X_val.shape: (4865, 124)\n",
      "y_val.shape: (4865, 1)\n",
      "\n",
      "Fold 4:\n",
      "X_subtrain.shape: (14173, 124)\n",
      "y_subtrain.shape: (14173, 1)\n",
      "X_val.shape: (2547, 124)\n",
      "y_val.shape: (2547, 1)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "6e6f9bf7a4fe5b68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:26:59.134389Z",
     "start_time": "2024-11-28T14:26:59.107403Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Get plus class data for train and test sets\n",
    "X_train_plus, y_train_plus = get_plus_cls(X_train, y_train, UPPER_THRESHOLD)\n",
    "X_test_plus, y_test_plus = get_plus_cls(X_test, y_test, UPPER_THRESHOLD)\n",
    "\n",
    "print(\"Plus (>= upper threshold) Shapes:\")\n",
    "print(f'X_train_plus.shape: {X_train_plus.shape}')\n",
    "print(f'y_train_plus.shape: {y_train_plus.shape}')\n",
    "print(f'X_test_plus.shape: {X_test_plus.shape}')\n",
    "print(f'y_test_plus.shape: {y_test_plus.shape}')\n",
    "print()\n",
    "\n",
    "# Get plus shapes for each fold\n",
    "print(\"Plus shapes for each fold:\")\n",
    "for i, (X_sub, y_sub, X_v, y_v) in enumerate(folds):\n",
    "    # Get plus data for subtrain and validation sets\n",
    "    X_sub_plus, y_sub_plus = get_plus_cls(X_sub, y_sub, UPPER_THRESHOLD)\n",
    "    X_v_plus, y_v_plus = get_plus_cls(X_v, y_v, UPPER_THRESHOLD)\n",
    "    \n",
    "    print(f'Fold {i+1}:')\n",
    "    print(f'X_subtrain_plus.shape: {X_sub_plus.shape}')\n",
    "    print(f'y_subtrain_plus.shape: {y_sub_plus.shape}')\n",
    "    print(f'X_val_plus.shape: {X_v_plus.shape}')\n",
    "    print(f'y_val_plus.shape: {y_v_plus.shape}')\n",
    "    print()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plus (>= upper threshold) Shapes:\n",
      "X_train_plus.shape: (920, 124)\n",
      "y_train_plus.shape: (920, 1)\n",
      "X_test_plus.shape: (424, 124)\n",
      "y_test_plus.shape: (424, 1)\n",
      "\n",
      "Plus shapes for each fold:\n",
      "Fold 1:\n",
      "X_subtrain_plus.shape: (656, 124)\n",
      "y_subtrain_plus.shape: (656, 1)\n",
      "X_val_plus.shape: (264, 124)\n",
      "y_val_plus.shape: (264, 1)\n",
      "\n",
      "Fold 2:\n",
      "X_subtrain_plus.shape: (785, 124)\n",
      "y_subtrain_plus.shape: (785, 1)\n",
      "X_val_plus.shape: (135, 124)\n",
      "y_val_plus.shape: (135, 1)\n",
      "\n",
      "Fold 3:\n",
      "X_subtrain_plus.shape: (600, 124)\n",
      "y_subtrain_plus.shape: (600, 1)\n",
      "X_val_plus.shape: (320, 124)\n",
      "y_val_plus.shape: (320, 1)\n",
      "\n",
      "Fold 4:\n",
      "X_subtrain_plus.shape: (719, 124)\n",
      "y_subtrain_plus.shape: (719, 1)\n",
      "X_val_plus.shape: (201, 124)\n",
      "y_val_plus.shape: (201, 1)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "f159d4f8ede4d80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:26:59.194604Z",
     "start_time": "2024-11-28T14:26:59.144408Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Get zero class data for train and test sets\n",
    "X_train_zero, y_train_zero = get_zero_cls(X_train, y_train, LOWER_THRESHOLD, UPPER_THRESHOLD)\n",
    "X_test_zero, y_test_zero = get_zero_cls(X_test, y_test, LOWER_THRESHOLD, UPPER_THRESHOLD)\n",
    "\n",
    "print(\"Zero (between thresholds) Shapes:\")\n",
    "print(f'X_train_zero.shape: {X_train_zero.shape}')\n",
    "print(f'y_train_zero.shape: {y_train_zero.shape}')\n",
    "print(f'X_test_zero.shape: {X_test_zero.shape}')\n",
    "print(f'y_test_zero.shape: {y_test_zero.shape}')\n",
    "print()\n",
    "\n",
    "# Get zero shapes for each fold\n",
    "print(\"Zero shapes for each fold:\")\n",
    "for i, (X_sub, y_sub, X_v, y_v) in enumerate(folds):\n",
    "    # Get zero data for subtrain and validation sets\n",
    "    X_sub_zero, y_sub_zero = get_zero_cls(X_sub, y_sub, LOWER_THRESHOLD, UPPER_THRESHOLD)\n",
    "    X_v_zero, y_v_zero = get_zero_cls(X_v, y_v, LOWER_THRESHOLD, UPPER_THRESHOLD)\n",
    "    \n",
    "    print(f'Fold {i+1}:')\n",
    "    print(f'X_subtrain_zero.shape: {X_sub_zero.shape}')\n",
    "    print(f'y_subtrain_zero.shape: {y_sub_zero.shape}')\n",
    "    print(f'X_val_zero.shape: {X_v_zero.shape}')\n",
    "    print(f'y_val_zero.shape: {y_v_zero.shape}')\n",
    "    print()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero (between thresholds) Shapes:\n",
      "X_train_zero.shape: (15070, 124)\n",
      "y_train_zero.shape: (15070, 1)\n",
      "X_test_zero.shape: (11105, 124)\n",
      "y_test_zero.shape: (11105, 1)\n",
      "\n",
      "Zero shapes for each fold:\n",
      "Fold 1:\n",
      "X_subtrain_zero.shape: (10793, 124)\n",
      "y_subtrain_zero.shape: (10793, 1)\n",
      "X_val_zero.shape: (4277, 124)\n",
      "y_val_zero.shape: (4277, 1)\n",
      "\n",
      "Fold 2:\n",
      "X_subtrain_zero.shape: (10768, 124)\n",
      "y_subtrain_zero.shape: (10768, 1)\n",
      "X_val_zero.shape: (4302, 124)\n",
      "y_val_zero.shape: (4302, 1)\n",
      "\n",
      "Fold 3:\n",
      "X_subtrain_zero.shape: (10764, 124)\n",
      "y_subtrain_zero.shape: (10764, 1)\n",
      "X_val_zero.shape: (4306, 124)\n",
      "y_val_zero.shape: (4306, 1)\n",
      "\n",
      "Fold 4:\n",
      "X_subtrain_zero.shape: (12885, 124)\n",
      "y_subtrain_zero.shape: (12885, 1)\n",
      "X_val_zero.shape: (2185, 124)\n",
      "y_val_zero.shape: (2185, 1)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "12d195b8347a372c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:26:59.210666Z",
     "start_time": "2024-11-28T14:26:59.196609Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Get minus class data for train and test sets\n",
    "X_train_minus, y_train_minus = get_minus_cls(X_train, y_train, LOWER_THRESHOLD)\n",
    "X_test_minus, y_test_minus = get_minus_cls(X_test, y_test, LOWER_THRESHOLD)\n",
    "\n",
    "print(\"Minus (below lower threshold) Shapes:\")\n",
    "print(f'X_train_minus.shape: {X_train_minus.shape}')\n",
    "print(f'y_train_minus.shape: {y_train_minus.shape}')\n",
    "print(f'X_test_minus.shape: {X_test_minus.shape}')\n",
    "print(f'y_test_minus.shape: {y_test_minus.shape}')\n",
    "print()\n",
    "\n",
    "# Get minus shapes for each fold\n",
    "print(\"Minus shapes for each fold:\")\n",
    "for i, (X_sub, y_sub, X_v, y_v) in enumerate(folds):\n",
    "    # Get minus data for subtrain and validation sets\n",
    "    X_sub_minus, y_sub_minus = get_minus_cls(X_sub, y_sub, LOWER_THRESHOLD)\n",
    "    X_v_minus, y_v_minus = get_minus_cls(X_v, y_v, LOWER_THRESHOLD)\n",
    "    \n",
    "    print(f'Fold {i+1}:')\n",
    "    print(f'X_subtrain_minus.shape: {X_sub_minus.shape}')\n",
    "    print(f'y_subtrain_minus.shape: {y_sub_minus.shape}')\n",
    "    print(f'X_val_minus.shape: {X_v_minus.shape}')\n",
    "    print(f'y_val_minus.shape: {y_v_minus.shape}')\n",
    "    print()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minus (below lower threshold) Shapes:\n",
      "X_train_minus.shape: (730, 124)\n",
      "y_train_minus.shape: (730, 1)\n",
      "X_test_minus.shape: (310, 124)\n",
      "y_test_minus.shape: (310, 1)\n",
      "\n",
      "Minus shapes for each fold:\n",
      "Fold 1:\n",
      "X_subtrain_minus.shape: (506, 124)\n",
      "y_subtrain_minus.shape: (506, 1)\n",
      "X_val_minus.shape: (224, 124)\n",
      "y_val_minus.shape: (224, 1)\n",
      "\n",
      "Fold 2:\n",
      "X_subtrain_minus.shape: (624, 124)\n",
      "y_subtrain_minus.shape: (624, 1)\n",
      "X_val_minus.shape: (106, 124)\n",
      "y_val_minus.shape: (106, 1)\n",
      "\n",
      "Fold 3:\n",
      "X_subtrain_minus.shape: (491, 124)\n",
      "y_subtrain_minus.shape: (491, 1)\n",
      "X_val_minus.shape: (239, 124)\n",
      "y_val_minus.shape: (239, 1)\n",
      "\n",
      "Fold 4:\n",
      "X_subtrain_minus.shape: (569, 124)\n",
      "y_subtrain_minus.shape: (569, 1)\n",
      "X_val_minus.shape: (161, 124)\n",
      "y_val_minus.shape: (161, 1)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "0bc59f4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:31:31.979311Z",
     "start_time": "2024-11-28T14:31:20.593195Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Set seed and parameters\n",
    "seed = SEEDS[0]\n",
    "inputs_to_use = INPUTS_TO_USE[0] \n",
    "add_slope = ADD_SLOPE[0]\n",
    "cme_speed_threshold = CME_SPEED_THRESHOLD[0]\n",
    "outputs_to_use = OUTPUTS_TO_USE\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "# Set root directory\n",
    "root_dir = 'C:/Users/the_3/Documents/github/keras-functional-api/data/electron_cme_data_split_v8'\n",
    "\n",
    "# Build training dataset\n",
    "X_train, y_train, _, _ = build_dataset(\n",
    "    root_dir + '/training',\n",
    "    inputs_to_use=inputs_to_use,\n",
    "    add_slope=add_slope,\n",
    "    outputs_to_use=outputs_to_use,\n",
    "    cme_speed_threshold=cme_speed_threshold,\n",
    "    shuffle_data=True)\n",
    "\n",
    "# Build test dataset\n",
    "X_test, y_test, _, _ = build_dataset(\n",
    "    root_dir + '/testing',\n",
    "    inputs_to_use=inputs_to_use,\n",
    "    add_slope=add_slope,\n",
    "    outputs_to_use=outputs_to_use,\n",
    "    cme_speed_threshold=cme_speed_threshold)\n",
    "\n",
    "# Convert labels to one-hot vectors\n",
    "y_train_classes = convert_to_onehot_cls(y_train, LOWER_THRESHOLD, UPPER_THRESHOLD)\n",
    "y_test_classes = convert_to_onehot_cls(y_test, LOWER_THRESHOLD, UPPER_THRESHOLD)\n",
    "\n",
    "# Print shapes for training and test data\n",
    "print(\"Training and Test Shapes with One-Hot Labels:\")\n",
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'y_train_classes.shape: {y_train_classes.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_test_classes.shape: {y_test_classes.shape}')\n",
    "print()\n",
    "\n",
    "# Process folds with one-hot encoded labels\n",
    "print(\"Fold Shapes with One-Hot Labels:\")\n",
    "for i, (X_sub, y_sub, X_v, y_v) in enumerate(load_stratified_folds(\n",
    "    root_dir,\n",
    "    inputs_to_use=inputs_to_use,\n",
    "    add_slope=add_slope,\n",
    "    outputs_to_use=outputs_to_use,\n",
    "    cme_speed_threshold=cme_speed_threshold,\n",
    "    seed=seed,\n",
    "    shuffle=True\n",
    ")):\n",
    "    # Convert fold labels to one-hot\n",
    "    y_sub_classes = convert_to_onehot_cls(y_sub, LOWER_THRESHOLD, UPPER_THRESHOLD)\n",
    "    y_v_classes = convert_to_onehot_cls(y_v, LOWER_THRESHOLD, UPPER_THRESHOLD)\n",
    "\n",
    "    print(f'Fold {i+1}:')\n",
    "    print(f'X_subtrain.shape: {X_sub.shape}')\n",
    "    print(f'y_subtrain_classes.shape: {y_sub_classes.shape}')\n",
    "    print(f'X_val.shape: {X_v.shape}')\n",
    "    print(f'y_val_classes.shape: {y_v_classes.shape}')\n",
    "    print()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Test Shapes with One-Hot Labels:\n",
      "X_train.shape: (16720, 124)\n",
      "y_train_classes.shape: (16720, 3)\n",
      "X_test.shape: (11839, 124)\n",
      "y_test_classes.shape: (11839, 3)\n",
      "\n",
      "Fold Shapes with One-Hot Labels:\n",
      "Fold 1:\n",
      "X_subtrain.shape: (11955, 124)\n",
      "y_subtrain_classes.shape: (11955, 3)\n",
      "X_val.shape: (4765, 124)\n",
      "y_val_classes.shape: (4765, 3)\n",
      "\n",
      "Fold 2:\n",
      "X_subtrain.shape: (12177, 124)\n",
      "y_subtrain_classes.shape: (12177, 3)\n",
      "X_val.shape: (4543, 124)\n",
      "y_val_classes.shape: (4543, 3)\n",
      "\n",
      "Fold 3:\n",
      "X_subtrain.shape: (11855, 124)\n",
      "y_subtrain_classes.shape: (11855, 3)\n",
      "X_val.shape: (4865, 124)\n",
      "y_val_classes.shape: (4865, 3)\n",
      "\n",
      "Fold 4:\n",
      "X_subtrain.shape: (14173, 124)\n",
      "y_subtrain_classes.shape: (14173, 3)\n",
      "X_val.shape: (2547, 124)\n",
      "y_val_classes.shape: (2547, 3)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:31:31.995207Z",
     "start_time": "2024-11-28T14:31:31.982224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print the first 3 elements of training one hot\n",
    "print(y_train_classes[:3])\n",
    "print(y_train[:3])"
   ],
   "id": "4071605df9b3fdfb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "[[-0.32598616]\n",
      " [ 0.24692117]\n",
      " [-0.02931396]]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "effd4c9d21355562",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modules'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodules\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mts_modeling\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m stratified_4fold_split\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'modules'"
     ]
    }
   ],
   "source": [
    "from modules.training.ts_modeling import stratified_4fold_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb3aaf00e3204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (X_subtrain, y_subtrain, X_val, y_val) in enumerate(stratified_4fold_split(X_train, y_train, seed=seed, debug=True)):\n",
    "    print(f'Fold {i + 1}:')\n",
    "    print(f'X_subtrain.shape: {X_subtrain.shape}')\n",
    "    print(f'y_subtrain.shape: {y_subtrain.shape}')\n",
    "    print(f'X_val.shape: {X_val.shape}')\n",
    "    print(f'y_val.shape: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2a9f9e4d8f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jensenshannon\n",
    "import numpy as np\n",
    "from typing import Dict, Union\n",
    "\n",
    "\n",
    "def calculate_js_divergence(X1: np.ndarray, X2: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate the Jensen-Shannon (JS) divergence for each feature between two datasets.\n",
    "\n",
    "    Args:\n",
    "        X1 (np.ndarray): The first dataset (e.g., training data) with shape (n_samples, n_features).\n",
    "        X2 (np.ndarray): The second dataset (e.g., test data) with shape (n_samples, n_features).\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: A dictionary where the keys are feature names (or indices) \n",
    "                          and the values are the corresponding JS divergence values.\n",
    "    \"\"\"\n",
    "    js_divergences = {}\n",
    "    n_features = X1.shape[1]  # Number of features\n",
    "\n",
    "    # Iterate over each feature index\n",
    "    for i in range(n_features):\n",
    "        # Create a histogram for the feature in each dataset\n",
    "        p = np.histogram(X1[:, i], bins=100, density=True)[0]\n",
    "        q = np.histogram(X2[:, i], bins=100, density=True)[0]\n",
    "\n",
    "        # Calculate the JS divergence between the two histograms\n",
    "        js_div = jensenshannon(p, q)\n",
    "\n",
    "        # Store the JS divergence in the dictionary with the feature index as the key\n",
    "        js_divergences[f'Feature_{i}'] = js_div\n",
    "\n",
    "    return js_divergences\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def calculate_js_divergence_labels(y1: Union[np.ndarray, list], y2: Union[np.ndarray, list], bin_width: float = 0.1,\n",
    "                                   plot: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Jensen-Shannon (JS) divergence between the label distributions of two regression datasets.\n",
    "    Optionally, plot the histograms of the label distributions.\n",
    "\n",
    "    Args:\n",
    "        y1 (Union[np.ndarray, list]): The labels for the first dataset (e.g., training labels).\n",
    "        y2 (Union[np.ndarray, list]): The labels for the second dataset (e.g., test labels).\n",
    "        plot (bool): If True, plot the histograms of the label distributions. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        float: The JS divergence between the label distributions.\n",
    "    \"\"\"\n",
    "    # Define the bin edges for the histograms with width 0.1 between -2.5 and 2.5\n",
    "    bins = np.arange(-2.5, 2.5 + bin_width, bin_width)\n",
    "\n",
    "    # Calculate histograms for the labels with the same bins for both datasets\n",
    "    p = np.histogram(y1, bins=bins, density=True)[0]\n",
    "    q = np.histogram(y2, bins=bins, density=True)[0]\n",
    "\n",
    "    # Calculate the JS divergence between the two label distributions\n",
    "    js_div = jensenshannon(p, q)\n",
    "\n",
    "    # Plot the histograms if requested\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Plot the histogram for the first dataset\n",
    "        plt.hist(y1, bins=bins, density=True, alpha=0.5, color='blue', label='Dataset 1 (y1)')\n",
    "\n",
    "        # Plot the histogram for the second dataset\n",
    "        plt.hist(y2, bins=bins, density=True, alpha=0.5, color='orange', label='Dataset 2 (y2)')\n",
    "\n",
    "        # Adding labels and title\n",
    "        plt.xlabel('Label Value')\n",
    "        plt.ylabel('Density')\n",
    "        plt.title('Label Distribution Comparison')\n",
    "        plt.legend(loc='upper right')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n",
    "    return js_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee55cebc14ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate JS divergence for features\n",
    "js_train_test = calculate_js_divergence(X_train, X_test)\n",
    "js_subtrain_test = calculate_js_divergence(X_subtrain, X_test)\n",
    "js_val_test = calculate_js_divergence(X_val, X_test)\n",
    "\n",
    "# Calculate JS divergence for labels\n",
    "js_labels_train_test = calculate_js_divergence_labels(y_train, y_test, bin_width=0.01, plot=True)\n",
    "js_labels_subtrain_test = calculate_js_divergence_labels(y_subtrain, y_test, bin_width=0.01, plot=True)\n",
    "js_labels_val_test = calculate_js_divergence_labels(y_val, y_test, bin_width=0.01, plot=True)\n",
    "\n",
    "# Print all JS divergences for features\n",
    "print(f'Seed: {seed}, Inputs: {inputs_to_use}, Add Slope: {add_slope}, CME Speed Threshold: {cme_speed_threshold}')\n",
    "print('JS Divergence between X_train and X_test:')\n",
    "for feature, js_div in js_train_test.items():\n",
    "    print(f'Feature: {feature}, JS Divergence: {js_div:.4f}')\n",
    "\n",
    "print('JS Divergence between X_subtrain and X_test:')\n",
    "for feature, js_div in js_subtrain_test.items():\n",
    "    print(f'Feature: {feature}, JS Divergence: {js_div:.4f}')\n",
    "\n",
    "print('JS Divergence between X_val and X_test:')\n",
    "for feature, js_div in js_val_test.items():\n",
    "    print(f'Feature: {feature}, JS Divergence: {js_div:.4f}')\n",
    "\n",
    "# Print average JS divergences for features\n",
    "avg_js_train_test = np.mean(list(js_train_test.values()))\n",
    "avg_js_subtrain_test = np.mean(list(js_subtrain_test.values()))\n",
    "avg_js_val_test = np.mean(list(js_val_test.values()))\n",
    "print(f'Average JS Divergence between X_train and X_test: {avg_js_train_test:.4f}')\n",
    "print(f'Average JS Divergence between X_subtrain and X_test: {avg_js_subtrain_test:.4f}')\n",
    "print(f'Average JS Divergence between X_val and X_test: {avg_js_val_test:.4f}')\n",
    "\n",
    "# Print JS divergences for labels\n",
    "print(f'JS Divergence between y_train and y_test: {js_labels_train_test:.4f}')\n",
    "print(f'JS Divergence between y_subtrain and y_test: {js_labels_subtrain_test:.4f}')\n",
    "print(f'JS Divergence between y_val and y_test: {js_labels_val_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9391ee4bed8e01",
   "metadata": {},
   "source": [
    "### Summary: Jensen-Shannon (JS) Divergence\n",
    "\n",
    "- **JS Divergence**: Measures the similarity between two probability distributions.\n",
    "- **Range**: 0 (identical) to 1 (completely dissimilar).\n",
    "- **Good Value**: JS close to 0 indicates similar distributions.\n",
    "- **Bad Value**: JS close to 1 indicates significant differences.\n",
    "\n",
    "### Results for Your Dataset\n",
    "\n",
    "- **y_train vs. y_test**: JS = 0.0861\n",
    "- **y_subtrain vs. y_test**: JS = 0.0867\n",
    "- **y_val vs. y_test**: JS = 0.0943\n",
    "\n",
    "These relatively low JS values suggest that the label distributions in your training, subtraining, validation, and test sets are quite similar. While the divergences are not negligible, they are still well within a range that generally indicates good distributional alignment. This implies that your model should be able to generalize well across these datasets, with minimal risk of performance degradation due to distributional differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b3facf230cfdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_js_divergence_labels_subset(y1: Union[np.ndarray, list], y2: Union[np.ndarray, list],\n",
    "                                          bin_width: float = 0.1, lower_b: float = -2.5,\n",
    "                                          higher_b: float = 2.5, plot: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Jensen-Shannon (JS) divergence between the label distributions of two regression datasets\n",
    "    within a specified subset range. Optionally, plot the histograms of the label distributions.\n",
    "\n",
    "    Args:\n",
    "        y1 (Union[np.ndarray, list]): The labels for the first dataset (e.g., training labels).\n",
    "        y2 (Union[np.ndarray, list]): The labels for the second dataset (e.g., test labels).\n",
    "        bin_width (float): The width of the bins for the histograms. Default is 0.1.\n",
    "        lower_b (float): The lower bound of the subset range to consider. Default is -2.5.\n",
    "        higher_b (float): The upper bound of the subset range to consider. Default is 2.5.\n",
    "        plot (bool): If True, plot the histograms of the label distributions. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        float: The JS divergence between the label distributions within the specified range.\n",
    "    \"\"\"\n",
    "    # Filter the data to consider only the subset within the specified range\n",
    "    y1_subset = np.array([y for y in y1 if lower_b <= y <= higher_b])\n",
    "    y2_subset = np.array([y for y in y2 if lower_b <= y <= higher_b])\n",
    "\n",
    "    # Define the bin edges for the histograms with the specified bin width within the given range\n",
    "    bins = np.arange(lower_b, higher_b + bin_width, bin_width)\n",
    "\n",
    "    # Calculate histograms for the labels with the same bins for both datasets\n",
    "    p = np.histogram(y1_subset, bins=bins, density=True)[0]\n",
    "    q = np.histogram(y2_subset, bins=bins, density=True)[0]\n",
    "\n",
    "    # Calculate the JS divergence between the two label distributions\n",
    "    js_div = jensenshannon(p, q)\n",
    "\n",
    "    # Plot the histograms if requested\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Plot the histogram for the first dataset\n",
    "        plt.hist(y1_subset, bins=bins, density=True, alpha=0.5, color='blue', label='Dataset 1 (y1)')\n",
    "\n",
    "        # Plot the histogram for the second dataset\n",
    "        plt.hist(y2_subset, bins=bins, density=True, alpha=0.5, color='orange', label='Dataset 2 (y2)')\n",
    "\n",
    "        # Adding labels and title\n",
    "        plt.xlabel('Label Value')\n",
    "        plt.ylabel('Density')\n",
    "        plt.title(f'Label Distribution Comparison (Subset between {lower_b} and {higher_b})')\n",
    "        plt.legend(loc='upper right')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n",
    "    return js_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab2a1d4218f9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = 0.5\n",
    "upper_bound = 2.5\n",
    "\n",
    "# Calculate JS divergence for labels within the subset range\n",
    "js_labels_train_test_subset = calculate_js_divergence_labels_subset(y_train, y_test, lower_b=lower_bound,\n",
    "                                                                    higher_b=upper_bound, bin_width=0.01, plot=True)\n",
    "js_labels_subtrain_test_subset = calculate_js_divergence_labels_subset(y_subtrain, y_test, lower_b=lower_bound,\n",
    "                                                                       higher_b=upper_bound, bin_width=0.01, plot=True)\n",
    "js_labels_val_test_subset = calculate_js_divergence_labels_subset(y_val, y_test, lower_b=lower_bound,\n",
    "                                                                  higher_b=upper_bound, bin_width=0.01, plot=True)\n",
    "\n",
    "# Print JS divergences for labels within the subset range\n",
    "print(\n",
    "    f'JS Divergence between y_train and y_test (Subset between {lower_bound} and {upper_bound}): {js_labels_train_test_subset:.4f}')\n",
    "print(\n",
    "    f'JS Divergence between y_subtrain and y_test (Subset between {lower_bound} and {upper_bound}): {js_labels_subtrain_test_subset:.4f}')\n",
    "print(\n",
    "    f'JS Divergence between y_val and y_test (Subset between {lower_bound} and {upper_bound}): {js_labels_val_test_subset:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc577161bda100",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = 0.5\n",
    "upper_bound = 2.5\n",
    "\n",
    "# Calculate JS divergence for labels within the subset range\n",
    "# js_labels_train_test_subset = calculate_js_divergence_labels_subset(y_train, y_test, lower_b=lower_bound,\n",
    "#                                                                     higher_b=upper_bound, bin_width=0.01, plot=True)\n",
    "# js_labels_subtrain_test_subset = calculate_js_divergence_labels_subset(y_subtrain, y_test, lower_b=lower_bound,\n",
    "#                                                                        higher_b=upper_bound, bin_width=0.01, plot=True)\n",
    "js_labels_val_test_subset = calculate_js_divergence_labels_subset(y_val, y_train, lower_b=lower_bound,\n",
    "                                                                  higher_b=upper_bound, bin_width=0.1, plot=True)\n",
    "\n",
    "\n",
    "# Print JS divergences for labels within the subset range\n",
    "# print(\n",
    "#     f'JS Divergence between y_train and y_test (Subset between {lower_bound} and {upper_bound}): {js_labels_train_test_subset:.4f}')\n",
    "# print(\n",
    "#     f'JS Divergence between y_subtrain and y_test (Subset between {lower_bound} and {upper_bound}): {js_labels_subtrain_test_subset:.4f}')\n",
    "print(\n",
    "    f'JS Divergence between y_val and y_train (Subset between {lower_bound} and {upper_bound}): {js_labels_val_test_subset:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe51c607115fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = -2.5\n",
    "upper_bound = 2.5\n",
    "\n",
    "# Calculate JS divergence for labels within the subset range\n",
    "# js_labels_train_test_subset = calculate_js_divergence_labels_subset(y_train, y_test, lower_b=lower_bound,\n",
    "#                                                                     higher_b=upper_bound, bin_width=0.01, plot=True)\n",
    "# js_labels_subtrain_test_subset = calculate_js_divergence_labels_subset(y_subtrain, y_test, lower_b=lower_bound,\n",
    "#                                                                        higher_b=upper_bound, bin_width=0.01, plot=True)\n",
    "js_labels_val_test_subset = calculate_js_divergence_labels_subset(y_val, y_train, lower_b=lower_bound,\n",
    "                                                                  higher_b=upper_bound, bin_width=0.01, plot=True)\n",
    "\n",
    "\n",
    "# Print JS divergences for labels within the subset range\n",
    "# print(\n",
    "#     f'JS Divergence between y_train and y_test (Subset between {lower_bound} and {upper_bound}): {js_labels_train_test_subset:.4f}')\n",
    "# print(\n",
    "#     f'JS Divergence between y_subtrain and y_test (Subset between {lower_bound} and {upper_bound}): {js_labels_subtrain_test_subset:.4f}')\n",
    "print(\n",
    "    f'JS Divergence between y_val and y_train (Subset between {lower_bound} and {upper_bound}): {js_labels_val_test_subset:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c89180813fb450",
   "metadata": {},
   "source": [
    "### Analysis of JS Divergence for the Subset between 0.5 and 2.5\n",
    "\n",
    "- **JS Divergence between `y_train` and `y_test` (Subset 0.5 to 2.5): 0.4015**\n",
    "- **JS Divergence between `y_subtrain` and `y_test` (Subset 0.5 to 2.5): 0.3993**\n",
    "- **JS Divergence between `y_val` and `y_test` (Subset 0.5 to 2.5): 0.5027**\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **Higher JS Divergence**:\n",
    "  - These JS divergence values are notably higher than those observed for the full dataset range. Specifically, the divergence values range from approximately 0.4 to 0.5.\n",
    "  - **0.4015** and **0.3993** indicate a moderate difference between the training, subtraining, and test label distributions.\n",
    "  - **0.5027** is quite high, particularly for the validation set compared to the test set, suggesting a more significant difference in this subset range.\n",
    "\n",
    "### Implications:\n",
    "\n",
    "- **Potential Distributional Shift**: The higher JS divergence in this specific range (0.5 to 2.5) suggests that there is a notable difference in how the labels are distributed in this region between your training, subtraining, validation, and test sets. This could indicate a distributional shift, particularly in the validation set, that may affect model performance in this range.\n",
    "- **Impact on Model Performance**:\n",
    "  - If this range (0.5 to 2.5) is particularly important for your prediction task, the model might struggle to generalize well in this interval due to the distributional differences.\n",
    "  - The validation set having the highest divergence (**0.5027**) compared to the test set could lead to validation performance not accurately reflecting the test performance.\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa76d39adb4d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = -2.5\n",
    "higher_bound = -0.5\n",
    "\n",
    "# Calculate JS divergence for labels within the subset range\n",
    "js_labels_train_test_subset = calculate_js_divergence_labels_subset(y_train, y_test, lower_b=lower_bound,\n",
    "                                                                    higher_b=higher_bound, bin_width=0.01, plot=True)\n",
    "js_labels_subtrain_test_subset = calculate_js_divergence_labels_subset(y_subtrain, y_test, lower_b=lower_bound,\n",
    "                                                                       higher_b=higher_bound, bin_width=0.01, plot=True)\n",
    "js_labels_val_test_subset = calculate_js_divergence_labels_subset(y_val, y_test, lower_b=lower_bound,\n",
    "                                                                    higher_b=higher_bound, bin_width=0.01, plot=True)\n",
    "\n",
    "# Print JS divergences for labels within the subset range\n",
    "print(\n",
    "    f'JS Divergence between y_train and y_test (Subset between {lower_bound} and {higher_bound}): {js_labels_train_test_subset:.4f}')\n",
    "print(\n",
    "    f'JS Divergence between y_subtrain and y_test (Subset between {lower_bound} and {higher_bound}): {js_labels_subtrain_test_subset:.4f}')\n",
    "print(\n",
    "    f'JS Divergence between y_val and y_test (Subset between {lower_bound} and {higher_bound}): {js_labels_val_test_subset:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8ab202aa38971d",
   "metadata": {},
   "source": [
    "### Analysis of JS Divergence for the Subset between -2.5 and -0.5\n",
    "\n",
    "- **JS Divergence between `y_train` and `y_test` (Subset -2.5 to -0.5): 0.4991**\n",
    "- **JS Divergence between `y_subtrain` and `y_test` (Subset -2.5 to -0.5): 0.5104**\n",
    "- **JS Divergence between `y_val` and `y_test` (Subset -2.5 to -0.5): 0.5238**\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **High JS Divergence**:\n",
    "  - These JS divergence values are quite high, close to or exceeding 0.5, which indicates significant differences in the label distributions between your datasets in the subset range from -2.5 to -0.5.\n",
    "  - **0.4991** for `y_train` vs. `y_test` and **0.5104** for `y_subtrain` vs. `y_test` suggest that the training and subtraining sets differ notably from the test set in this range.\n",
    "  - **0.5238** for `y_val` vs. `y_test` is the highest, indicating that the validation set is particularly different from the test set in this range.\n",
    "\n",
    "### Implications:\n",
    "\n",
    "- **Significant Distributional Shift**: The JS divergence values above 0.5 suggest that there is a substantial shift in label distributions between your datasets in the interval from -2.5 to -0.5. This is a strong indicator that the model trained on these data might not generalize well to the test set, especially in this specific range.\n",
    "- **Model Performance Concerns**:\n",
    "  - The model's performance in the range from -2.5 to -0.5 could be severely affected due to these high divergence values. Predictions in this region might be less accurate, as the training and validation sets do not represent the test set well in this interval.\n",
    "  - The highest divergence in the validation set (**0.5238**) suggests that validation performance may not be a reliable indicator of test performance in this range, potentially leading to over- or under-estimation of the model's capability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a5f363b467c417",
   "metadata": {},
   "source": [
    "# Debugging of stratified batch sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16dd636ba0b88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.training.ts_modeling import stratified_groups, stratified_data_generator, stratified_batch_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b2337a57870f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_groups = stratified_groups(y_val, batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2312d576d5941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the size of the whole groups and each group\n",
    "print(f'Shape of the whole groups: {val_groups.shape}')\n",
    "print(f'Total number of groups: {len(val_groups)}')\n",
    "print(f'Sizes of each group: {[len(group) for group in val_groups]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3f2594b039f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 elements of each group\n",
    "for i, group in enumerate(val_groups):\n",
    "    print(f'Group {i}: {group[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493c2eafb4a6536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print last 5 elements of each group\n",
    "for i, group in enumerate(val_groups):\n",
    "    print(f'Group {i}: {group[-5:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52599778321bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first batch of the stratified data generator\n",
    "strat_gen = stratified_data_generator(X_val, y_val, groups=val_groups, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f4b963d8ead506",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = next(strat_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ad5382d1c8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print min and max y in batch\n",
    "import numpy as np\n",
    "print(f'Min y in batch: {np.min(y_batch)}')\n",
    "print(f'Max y in batch: {np.max(y_batch)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35521a265c5cc9c",
   "metadata": {},
   "source": [
    "## checking if the peak delta and peak intensity are correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ef2049b51cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'C:/Users/the_3/Documents/github/keras-functional-api/data/electron_cme_data_split_v7/full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6fc4780b4252e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc1bb320c0c26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peak_values(directory_path: str) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract peak values from proton intensity data files in a directory.\n",
    "    \n",
    "    This function processes CSV files containing proton intensity data and extracts:\n",
    "    - Peak log-transformed proton intensity values\n",
    "    - Peak delta log intensity values \n",
    "    - Event IDs\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): Path to directory containing proton intensity CSV files\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Contains three numpy arrays (all sorted by event ID):\n",
    "            - peak_log_intensity_array: Array of peak log-transformed proton intensities\n",
    "            - peak_delta_array: Array of peak delta log intensities\n",
    "            - event_indices_array: Array of event IDs\n",
    "    \"\"\"\n",
    "    # Initialize lists to store peak values and event IDs\n",
    "    peak_log_intensity_list = []\n",
    "    peak_delta_list = []\n",
    "    event_indices = []\n",
    "\n",
    "    # Get list of files ending with '_ie_trim.csv'\n",
    "    # These files contain the proton intensity data for each event\n",
    "    file_names = [f for f in os.listdir(directory_path) if f.endswith('_ie_trim.csv')]\n",
    "\n",
    "    for file_name in file_names:\n",
    "        # Construct full file path and read CSV\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # Extract relevant columns from the data\n",
    "        proton_intensity = data['Proton Intensity']\n",
    "        delta_log_intensity = data['delta_log_Intensity']\n",
    "        \n",
    "        # Get event ID from first row (assumed constant throughout file)\n",
    "        event_id = data['Event ID'].iloc[0]\n",
    "\n",
    "        # Transform proton intensity using log1p (log(1+x))\n",
    "        # This helps handle small values and maintains non-negativity\n",
    "        log_proton_intensity = np.log1p(proton_intensity)\n",
    "\n",
    "        # Calculate peak values for this event\n",
    "        peak_log_intensity = log_proton_intensity.max()\n",
    "        peak_delta = delta_log_intensity.max()\n",
    "\n",
    "        # Store values for this event\n",
    "        peak_log_intensity_list.append(peak_log_intensity)\n",
    "        peak_delta_list.append(peak_delta)\n",
    "        event_indices.append(event_id)\n",
    "\n",
    "    # Convert lists to numpy arrays for efficient processing\n",
    "    peak_log_intensity_array = np.array(peak_log_intensity_list)\n",
    "    peak_delta_array = np.array(peak_delta_list)\n",
    "    event_indices_array = np.array(event_indices)\n",
    "\n",
    "    # Sort all arrays based on event IDs to ensure consistent ordering\n",
    "    sorted_indices = np.argsort(event_indices_array)\n",
    "    peak_log_intensity_array = peak_log_intensity_array[sorted_indices]\n",
    "    peak_delta_array = peak_delta_array[sorted_indices]\n",
    "    event_indices_array = event_indices_array[sorted_indices]\n",
    "\n",
    "    return peak_log_intensity_array, peak_delta_array, event_indices_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c5c5b16587858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_array(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize an array to the range [0,1] using min-max normalization.\n",
    "    \n",
    "    Args:\n",
    "        arr (np.ndarray): Input array to normalize\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Normalized array with values scaled to [0,1]\n",
    "    \"\"\"\n",
    "    # Calculate min and max once to avoid repeated computation\n",
    "    arr_min = arr.min()\n",
    "    arr_max = arr.max()\n",
    "    \n",
    "    # Normalize using min-max scaling formula: (x - min)/(max - min)\n",
    "    return (arr - arr_min) / (arr_max - arr_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c58e7a4b42e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peak_values(peak_log_intensity: np.ndarray, \n",
    "                     peak_delta: np.ndarray, \n",
    "                     event_indices: np.ndarray,\n",
    "                     event_color: bool = False,\n",
    "                     norm_axis: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Create a scatter plot comparing peak log proton intensity vs peak delta values.\n",
    "    \n",
    "    Args:\n",
    "        peak_log_intensity (np.ndarray): Array of peak log proton intensity values\n",
    "        peak_delta (np.ndarray): Array of peak delta values \n",
    "        event_indices (np.ndarray): Array of event indices used for coloring the scatter points\n",
    "        event_color (bool): Whether to color points by event index (default False)\n",
    "        norm_axis (bool): Whether to normalize the axis values to [0,1] range (default True)\n",
    "        \n",
    "    Returns:\n",
    "        None: Displays the plot using plt.show()\n",
    "    \"\"\"\n",
    "    # Normalize arrays if requested\n",
    "    x_values = normalize_array(peak_log_intensity) if norm_axis else peak_log_intensity\n",
    "    y_values = normalize_array(peak_delta) if norm_axis else peak_delta\n",
    "\n",
    "    # Create figure with reasonable size for visualization\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Create scatter plot with optional event index coloring\n",
    "    if event_color:\n",
    "        scatter = plt.scatter(x_values, y_values, \n",
    "                            c=event_indices, cmap='viridis')\n",
    "        # Add colorbar to show event index scale\n",
    "        plt.colorbar(scatter, label='Event Index')\n",
    "    else:\n",
    "        plt.scatter(x_values, y_values)\n",
    "    \n",
    "    # Add diagonal reference line if normalized\n",
    "    if norm_axis:\n",
    "        plt.plot([0,1], [0,1], linestyle='--', color='gray')\n",
    "    \n",
    "    # Label axes and title\n",
    "    x_label = 'Normalized ' if norm_axis else ''\n",
    "    y_label = 'Normalized ' if norm_axis else ''\n",
    "    plt.xlabel(f'{x_label}Peak Log Proton Intensity')\n",
    "    plt.ylabel(f'{y_label}Peak Delta')\n",
    "    plt.title('Peak Log Proton Intensity vs Peak Delta')\n",
    "    \n",
    "    # Add grid for better readability\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc32406eb17e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "directory_path = root_dir\n",
    "peak_log_intensity_array, peak_delta_array, event_indices_array = get_peak_values(directory_path)\n",
    "print(\"\\nEvent Index | Peak Log Intensity | Peak Delta\")\n",
    "print(\"-\" * 45)\n",
    "for i, (intensity, delta, event) in enumerate(zip(peak_log_intensity_array, peak_delta_array, event_indices_array)):\n",
    "    print(f\"{event:^11d} | {intensity:^17.4f} | {delta:^10.4f}\")\n",
    "\n",
    "plot_peak_values(peak_log_intensity_array, peak_delta_array, event_indices_array)\n",
    "\n",
    "# Plot unnormalized version\n",
    "plot_peak_values(peak_log_intensity_array, peak_delta_array, event_indices_array, norm_axis=False)\n",
    "\n",
    "# Sort events by peak delta in descending order and display\n",
    "sorted_indices = np.argsort(peak_delta_array)[::-1]\n",
    "print(\"\\nEvents sorted by peak delta (descending):\")\n",
    "print(\"Event Index | Peak Delta | Peak Log Intensity\")\n",
    "print(\"-\" * 45)\n",
    "for idx in sorted_indices:\n",
    "    event = event_indices_array[idx]\n",
    "    intensity = peak_log_intensity_array[idx] \n",
    "    delta = peak_delta_array[idx]\n",
    "    print(f\"{event:^11d} | {delta:^10.4f} | {intensity:^17.4f}\")\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Original scatter with events colored by sorted index\n",
    "scatter1 = ax1.scatter(peak_log_intensity_array, peak_delta_array,\n",
    "                      c=np.arange(len(sorted_indices)), cmap='viridis')\n",
    "ax1.set_xlabel('Peak Log Proton Intensity')\n",
    "ax1.set_ylabel('Peak Delta')\n",
    "ax1.set_title('Events Colored by Original Order')\n",
    "ax1.grid(True)\n",
    "plt.colorbar(scatter1, ax=ax1, label='Event Order')\n",
    "\n",
    "# Plot 2: Scatter with events colored by peak delta value\n",
    "scatter2 = ax2.scatter(peak_log_intensity_array, peak_delta_array,\n",
    "                      c=peak_delta_array, cmap='viridis')\n",
    "ax2.set_xlabel('Peak Log Proton Intensity')\n",
    "ax2.set_ylabel('Peak Delta')\n",
    "ax2.set_title('Events Colored by Peak Delta')\n",
    "ax2.grid(True)\n",
    "plt.colorbar(scatter2, ax=ax2, label='Peak Delta')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadee244",
   "metadata": {},
   "source": [
    "### Testing if Jesse's plot reduced down to persistent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871fd99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d49b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_sep_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads the SEP event data from the specified file path.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the SEP event file.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The SEP event data as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_persistent_model(\n",
    "    test_set_path: str,\n",
    "    output_file: str = 'persistent_model_with_delta_plot.png',\n",
    "    colormap: str = 'viridis'\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots the log proton intensity (actual proton) on the x-axis against the persistent model (p_t_log) on the y-axis,\n",
    "    with the color being the actual proton intensity using the specified colormap. Also plots the actual delta values\n",
    "    against the persistent model delta (which is zero), with the color being the actual delta values. Both plots are \n",
    "    displayed side by side.\n",
    "\n",
    "    Parameters:\n",
    "    - test_set_path (str): Path to the directory containing the test set SEP event files.\n",
    "    - output_file (str): Filename to save the plot. Default is 'persistent_model_with_delta_plot.png'.\n",
    "    - colormap (str): Colormap to use for the scatter plots. Default is 'viridis'.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Initialize lists to hold data\n",
    "    actual_proton_logs = []\n",
    "    p_t_logs = []\n",
    "    actual_protons = []\n",
    "    actual_deltas = []\n",
    "    persistent_deltas = []\n",
    "\n",
    "    # Iterate over files in the test_set_path\n",
    "    for file_name in os.listdir(test_set_path):\n",
    "        if file_name.endswith('_ie_trim.csv'):\n",
    "            file_path = os.path.join(test_set_path, file_name)\n",
    "            try:\n",
    "                # Read the SEP event data\n",
    "                df = read_sep_data(file_path)\n",
    "\n",
    "                # Skip files where proton intensity is -9999\n",
    "                if (df['Proton Intensity'] == -9999).any():\n",
    "                    continue\n",
    "\n",
    "                # Compute actual proton intensity and its log\n",
    "                actual_proton = df['Proton Intensity'].values\n",
    "                actual_proton_log = np.log1p(actual_proton)\n",
    "\n",
    "                # Compute p_t_log (persistent model)\n",
    "                p_t = df['p_t'].values\n",
    "                p_t_log = np.log1p(p_t)\n",
    "\n",
    "                # Get actual delta values from dataset\n",
    "                delta_actual = df['delta_log_Intensity'].values\n",
    "\n",
    "                # Persistent model delta is zero (since the persistent model assumes no change)\n",
    "                delta_persistent = np.zeros_like(delta_actual)\n",
    "\n",
    "                # Append data to lists\n",
    "                actual_protons.extend(actual_proton)\n",
    "                actual_proton_logs.extend(actual_proton_log)\n",
    "                p_t_logs.extend(p_t_log)\n",
    "                actual_deltas.extend(delta_actual)\n",
    "                persistent_deltas.extend(delta_persistent)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file: {file_name}\")\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "    # Check if data is collected\n",
    "    if len(actual_proton_logs) == 0:\n",
    "        print(\"No data to plot.\")\n",
    "        return\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    actual_proton_logs = np.array(actual_proton_logs)\n",
    "    p_t_logs = np.array(p_t_logs)\n",
    "    actual_protons = np.array(actual_protons)\n",
    "    actual_deltas = np.array(actual_deltas)\n",
    "    persistent_deltas = np.array(persistent_deltas)\n",
    "\n",
    "    # Calculate the Pearson correlation coefficient for intensities\n",
    "    correlation_coef_intensity = np.corrcoef(actual_proton_logs, p_t_logs)[0, 1]\n",
    "    print(f\"Pearson correlation coefficient (Intensity): {correlation_coef_intensity:.4f}\")\n",
    "\n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # Intensity Plot (Left)\n",
    "    scatter1 = axes[0].scatter(\n",
    "        actual_proton_logs,\n",
    "        p_t_logs,\n",
    "        c=actual_protons,\n",
    "        cmap=colormap,\n",
    "        alpha=0.7,\n",
    "        edgecolors='w',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "    cbar1 = fig.colorbar(scatter1, ax=axes[0])\n",
    "    cbar1.set_label('Actual Proton Intensity')\n",
    "\n",
    "    # Add diagonal line representing perfect correlation\n",
    "    min_val = min(min(actual_proton_logs), min(p_t_logs))\n",
    "    max_val = max(max(actual_proton_logs), max(p_t_logs))\n",
    "    axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect Correlation')\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[0].set_xlabel('Actual Proton ln(Intensity)')\n",
    "    axes[0].set_ylabel('Persistent Model Proton ln(Intensity)')\n",
    "    axes[0].set_title('Actual vs Persistent Model Proton ln(Intensity)')\n",
    "\n",
    "    # Add the correlation coefficient text to the plot\n",
    "    axes[0].text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        f'Pearson r = {correlation_coef_intensity:.4f}',\n",
    "        transform=axes[0].transAxes,\n",
    "        fontsize=12,\n",
    "        verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "    )\n",
    "\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Delta Plot (Right)\n",
    "    scatter2 = axes[1].scatter(\n",
    "        actual_deltas,\n",
    "        persistent_deltas,\n",
    "        c=actual_deltas,\n",
    "        cmap=colormap,\n",
    "        alpha=0.7,\n",
    "        edgecolors='w',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "    cbar2 = fig.colorbar(scatter2, ax=axes[1])\n",
    "    cbar2.set_label('Actual Delta ln(Intensity)')\n",
    "\n",
    "    # Add horizontal line at zero (persistent model delta)\n",
    "    axes[1].axhline(0, color='r', linestyle='--', label='Persistent Model Delta = 0')\n",
    "    axes[1].legend()\n",
    "\n",
    "    axes[1].set_xlabel('Actual Delta ln(Intensity)')\n",
    "    axes[1].set_ylabel('Persistent Model Delta ln(Intensity)')\n",
    "    axes[1].set_title('Actual Delta vs Persistent Model Delta')\n",
    "\n",
    "    # Removed statistics text from delta plot\n",
    "\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot to a file\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved plot to: {output_file}\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73574593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'path_to_test_set_directory' with the actual path to your test set directory\n",
    "root_dir = 'C:/Users/the_3/Documents/github/keras-functional-api/data/electron_cme_data_split_v7'\n",
    "test_dir = root_dir + '/testing'\n",
    "plot_persistent_model(test_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68d14dc",
   "metadata": {},
   "source": [
    "### Let's sort the events by peak delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a06d59b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
