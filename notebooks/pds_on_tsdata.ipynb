{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\the_3\\anaconda3\\envs\\aip\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\the_3\\anaconda3\\envs\\aip\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from ts_modeling import build_dataset, create_mlp, evaluate_model, process_sep_events\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from wandb.keras import WandbCallback\n",
    "from evaluate.utils import plot_tsne_pds\n",
    "from models import modeling\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T16:21:01.278278800Z",
     "start_time": "2024-01-26T16:20:55.648780900Z"
    }
   },
   "id": "9b940281c77235f3",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# SEEDING\n",
    "SEED = 42  # seed number \n",
    "\n",
    "# Set NumPy seed\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Set TensorFlow seed\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Set random seed\n",
    "random.seed(SEED)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T16:21:18.097780900Z",
     "start_time": "2024-01-26T16:21:18.037780100Z"
    }
   },
   "id": "f76875d8faf6e350",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mb = modeling.ModelBuilder()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T16:25:12.904184900Z",
     "start_time": "2024-01-26T16:25:11.079184100Z"
    }
   },
   "id": "f3e6c466b78f6b70",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for inputs_to_use in [['e0.5', 'e1.8', 'p']]:\n",
    "    for add_slope in [False]:\n",
    "        # PARAMS\n",
    "        # inputs_to_use = ['e0.5']\n",
    "        # add_slope = True\n",
    "\n",
    "        # Join the inputs_to_use list into a string, replace '.' with '_', and join with '-'\n",
    "        inputs_str = \"_\".join(input_type.replace('.', '_') for input_type in inputs_to_use)\n",
    "\n",
    "        # Construct the title\n",
    "        title = f'MLP_{inputs_str}_add_slope_{str(add_slope)}'\n",
    "\n",
    "        # Replace any other characters that are not suitable for filenames (if any)\n",
    "        title = title.replace(' ', '_').replace(':', '_')\n",
    "\n",
    "        # Create a unique experiment name with a timestamp\n",
    "        current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        experiment_name = f'{title}_{current_time}'\n",
    "\n",
    "        # Initialize wandb\n",
    "        wandb.init(project=\"mlp-ts-lowerlr\", name=experiment_name, config={\n",
    "            \"inputs_to_use\": inputs_to_use,\n",
    "            \"add_slope\": add_slope,\n",
    "        })\n",
    "\n",
    "        # set the root directory\n",
    "        root_dir = 'D:/College/Fall2023/electron_cme_v4/electron_cme_data_split'\n",
    "        # build the dataset\n",
    "        X_train, y_train = build_dataset(root_dir + '/training', inputs_to_use=inputs_to_use, add_slope=add_slope)\n",
    "        X_subtrain, y_subtrain = build_dataset(root_dir + '/subtraining', inputs_to_use=inputs_to_use,\n",
    "                                               add_slope=add_slope)\n",
    "        X_test, y_test = build_dataset(root_dir + '/testing', inputs_to_use=inputs_to_use, add_slope=add_slope)\n",
    "        X_val, y_val = build_dataset(root_dir + '/validation', inputs_to_use=inputs_to_use, add_slope=add_slope)\n",
    "\n",
    "        # print all data shapes\n",
    "        print(f'X_train.shape: {X_train.shape}')\n",
    "        print(f'y_train.shape: {y_train.shape}')\n",
    "        print(f'X_subtrain.shape: {X_subtrain.shape}')\n",
    "        print(f'y_subtrain.shape: {y_subtrain.shape}')\n",
    "        print(f'X_test.shape: {X_test.shape}')\n",
    "        print(f'y_test.shape: {y_test.shape}')\n",
    "        print(f'X_val.shape: {X_val.shape}')\n",
    "        print(f'y_val.shape: {y_val.shape}')\n",
    "\n",
    "        # print a sample of the training data\n",
    "        print(f'X_train[0]: {X_train[0]}')\n",
    "        print(f'y_train[0]: {y_train[0]}')\n",
    "\n",
    "        # get the number of features\n",
    "        n_features = X_train.shape[1]\n",
    "        print(f'n_features: {n_features}')\n",
    "        hiddens = [100, 100, 50]\n",
    "\n",
    "        # create the model\n",
    "        # mlp_model_sep = create_mlp(input_dim=n_features, hiddens=hiddens)\n",
    "        mlp_model_sep = modeling.create_mlp(input_dim=n_features, hiddens=hiddens)\n",
    "        mlp_model_sep.summary()\n",
    "\n",
    "        # Set the early stopping patience and learning rate as variables\n",
    "        patience = 50\n",
    "        learning_rate = 3e-5\n",
    "        weight_decay = 0 # higher weight decay\n",
    "        momentum_beta1 = 0.9 # higher momentum beta1\n",
    "\n",
    "        # Define the EarlyStopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_forecast_head_loss', patience=patience, verbose=1,\n",
    "                                       restore_best_weights=True)\n",
    "\n",
    "        # Compile the model with the specified learning rate\n",
    "        mlp_model_sep.compile(optimizer=AdamW(learning_rate=learning_rate,\n",
    "                                              weight_decay=weight_decay,\n",
    "                                              beta_1=momentum_beta1),\n",
    "                              loss={'forecast_head': 'mse'})\n",
    "\n",
    "        # Train the model with the callback\n",
    "        history = mlp_model_sep.fit(X_subtrain,\n",
    "                                    {'forecast_head': y_subtrain},\n",
    "                                    epochs=1000, batch_size=32,\n",
    "                                    validation_data=(X_val, {'forecast_head': y_val}),\n",
    "                                    callbacks=[early_stopping, WandbCallback()])\n",
    "\n",
    "        # Plot the training and validation loss\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        # save the plot\n",
    "        plt.savefig(f'mlp_loss_{title}.png')\n",
    "\n",
    "        # Determine the optimal number of epochs from early stopping\n",
    "        optimal_epochs = early_stopping.stopped_epoch - patience + 1  # Adjust for the offset\n",
    "        final_mlp_model_sep = create_mlp(input_dim=n_features,\n",
    "                                         hiddens=hiddens)  # Recreate the model architecture\n",
    "        final_mlp_model_sep.compile(optimizer=AdamW(learning_rate=learning_rate,\n",
    "                                                    weight_decay=weight_decay,\n",
    "                                                    beta_1=momentum_beta1),\n",
    "                                    loss={'forecast_head': 'mse'})  # Compile the model just like before\n",
    "        # Train on the full dataset\n",
    "        final_mlp_model_sep.fit(X_train, {'forecast_head': y_train}, epochs=optimal_epochs, batch_size=32,\n",
    "                                verbose=1)\n",
    "\n",
    "        # evaluate the model on test data\n",
    "        error_mae = evaluate_model(final_mlp_model_sep, X_test, y_test)\n",
    "        print(f'mae error: {error_mae}')\n",
    "        # Log the MAE error to wandb\n",
    "        wandb.log({\"mae_error\": error_mae})\n",
    "\n",
    "        # Process SEP event files in the specified directory\n",
    "        test_directory = root_dir + '/testing'\n",
    "        filenames = process_sep_events(\n",
    "            test_directory,\n",
    "            final_mlp_model_sep,\n",
    "            model_type='mlp',\n",
    "            title=title,\n",
    "            inputs_to_use=inputs_to_use,\n",
    "            add_slope=add_slope)\n",
    "\n",
    "        # Log the plot to wandb\n",
    "        for filename in filenames:\n",
    "            wandb.log({f'{filename}': wandb.Image(filename)})\n",
    "\n",
    "        # Finish the wandb run\n",
    "        wandb.finish()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "805d14319f3bee0f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
